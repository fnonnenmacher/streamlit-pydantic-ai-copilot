{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"examples/01_basic_demo/","title":"Basic Demo","text":""},{"location":"examples/01_basic_demo/#basic-demo","title":"Basic Demo","text":"<p>This basic demo demonstrates delegating tool calls to the user and rendering of Pydantic internal tool calls. It's full code can be found here.</p> <p></p>"},{"location":"examples/01_basic_demo/#run-the-example","title":"Run the example","text":"<p>Before running the example, ensure that your OpenAI API key is set in the <code>OPENAI_API_KEY</code> environment variable. Once configured, you can start the demo using the following command:</p> uv run sync --all-groupsuv run streamlit run examples/01_basic_demo.py"},{"location":"examples/01_basic_demo/#the-code","title":"The Code","text":""},{"location":"examples/01_basic_demo/#defining-the-agent","title":"Defining the agent","text":"<p>First, let's define a basic Pydantic AI agent along with a tool that we want to display in the UI later.</p> Python<pre><code>from pydantic_ai import Agent\nfrom pydantic_ai.models.openai import OpenAIModel\nfrom pydantic import BaseModel\nfrom datetime import datetime\nfrom textwrap import dedent\n\nbasic_demo_agent = Agent(\n    model=OpenAIModel(\"gpt-4o\"), # (1)\n    system_prompt=dedent(\n        \"\"\"\\\n        You are a helpful assistant. Always call the user by their name.\n        Use the ask_user_for_name tool to get the user's name.\"\"\"\n    ),\n    output_type=str,\n)\n\n\nclass CurrentDateResponse(BaseModel): # (2)\n    date: str\n\n\n@basic_demo_agent.tool_plain()\ndef get_current_time() -&gt; CurrentDateResponse:\n    time.sleep(5) # (3)\n    return CurrentDateResponse(date=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n</code></pre> <ol> <li>This example uses an OpenAI model, but you can substitute any other supported model provider as needed.</li> <li>The wrapper class for the tool result is included for demonstration purposes; in practice, you can return the result directly if preferred.</li> <li>The call to <code>sleep</code> is used to mimic a long-running tool operation.</li> </ol>"},{"location":"examples/01_basic_demo/#defining-a-stremalit-tool-to-collect-user-input","title":"Defining a Stremalit tool to collect user input","text":"<p>Next, we define the Streamlit tool that will prompt the user for input.</p> Python<pre><code>class AskUserForNameTool(StreamlitToolDefinition[str]): # (1)\n    def chat_block(self) -&gt; DeltaGenerator:\n        tool_message = st.chat_message(\"tool\", avatar=\"\ud83d\udd27\")\n        tool_message.write(\"Tool Call: _Asking the user for their name_\")\n        return tool_message\n\n    def handle(self) -&gt; str | None: # (2)\n        \"\"\"\n        Asks the user for their name.\n        \"\"\"\n        return self.chat_block().text_input(\"What is your name?\")\n\n    def render(self, args: dict[str, Any], result: ToolResult[str]): # (3)\n        self.chat_block().write(f\"User has entered name: {result.output}\")\n</code></pre> <ol> <li>To define a Streamlit tool, create a subclass of <code>StreamlitToolDefinition</code>.     This class is generic, allowing you to specify the output type for your tool.</li> <li>The <code>handle</code> method is responsible for collecting user input.</li> <li>The <code>render</code> method is invoked after the tool has completed.     Use it to display the user input or any additional information related to the tool's result.</li> </ol> <p>To define a Streamlit tool, create a subclass of <code>StreamlitToolDefinition</code>. This class is generic, allowing you to specify the output type for your tool.</p> <p>You can define any parameters you need\u2014these will be automatically mapped from the tool call. The docstring (pydoc comment) you provide for the <code>handle</code> method will be made available to the agent, giving it additional context about the tool's purpose and usage. Inside <code>handle</code>, you can use any Streamlit UI elements. Once the method returns a value other than <code>None</code>, the tool call is considered complete. The result is cached, so <code>handle</code> will not be called again on subsequent <code>st.rerun()</code> events.</p> <p>Instead, the <code>render</code> method is invoked after the tool has completed. Use it to display the user input or any additional information related to the tool's result.</p>"},{"location":"examples/01_basic_demo/#define-render-logic-for-pydantic-internal-tools","title":"Define render logic for Pydantic Internal tools","text":"<p>To define how the output of a Pydantic AI tool is displayed in Streamlit, create a subclass of <code>ToolRenderer</code> with the same output type as your Pydantic AI tool. Note that this type consistency is not enforced at compile time, so ensure they match to avoid runtime errors.</p> Python<pre><code>class GetCurrentTimeToolRenderer(ToolRenderer[CurrentDateResponse]):\n    def __init__(self):\n        super().__init__(\"get_current_time\") # (1)\n\n    def render(self, args: dict[str, Any], result: ToolResult[CurrentDateResponse]):\n        with st.chat_message(\"tool\", avatar=\"\ud83d\udd27\"):\n            st.write(f'_Calling get current time tool with args \"{args}\"_')\n            with st.spinner(\"Waiting for tool...\", show_time=True):\n                result.wait_for_completion() # (2)\n            assert result.output is not None\n            st.write(f\"_Tool returned: {result.output.date}_\")\n</code></pre> <ol> <li>Ensure the tool name needs to matches the Pydantic AI tool name</li> <li>wait for the tool to complete.</li> </ol> <p>It's important to note that the tool name used in your <code>ToolRenderer</code> must exactly match the name of the corresponding Pydantic AI tool. If you define your tool using the <code>@agent.tool</code> decorator, the tool name will be the method name.</p> <p>To provide a transparent user experience, this library triggers the <code>render</code> method as soon as the tool is called. However, at this point, the tool may not have finished executing, so the result might not be immediately available. Therefore, always call <code>result.wait_for_completion()</code> before accessing the result to ensure it is ready. For a better user experience, you can combine this with a Streamlit spinner, as demonstrated in the example above.</p>"},{"location":"examples/01_basic_demo/#agent-session","title":"Agent Session","text":"<p>Now let's wire it all together and create a <code>AgentSession</code>:</p> Python<pre><code>@st.cache_resource # (1)\ndef init_agent_session() -&gt; AgentSession[None, str]:\n    return AgentSession(basic_demo_agent, [AskUserForNameTool(), GetCurrentTimeToolRenderer()])\n\n\nagent_conversation = init_agent_session().get_or_create_conversation() # (2)\n</code></pre> <ol> <li>The <code>@st.cache_resource</code> decorator is important because it ensures that the agent session persists across Streamlit reruns, preventing the session from being recreated on every interaction.</li> <li>You can create a new conversation by providing a custom ID</li> </ol> <p>The <code>@st.cache_resource</code> decorator is crucial for ensuring that your agent session persists across Streamlit reruns, so the session isn't recreated with every user interaction. When initializing the session, be sure to pass in your previously defined tools and tool renderers as arguments.</p> <p>The <code>AgentSession</code> acts as the main entry point for managing conversations. To start or resume a conversation, call the <code>get_or_create_conversation()</code> method. You can optionally provide a custom conversation ID to allow users to have separate, individualized conversations.  By default, <code>get_or_create_conversation()</code> will generate a conversation tied to the current Streamlit session, ensuring continuity for each user.</p>"},{"location":"examples/01_basic_demo/#streamlit-app","title":"Streamlit App","text":"<p>Finally, let's put everything together and build the Streamlit app:</p> Python<pre><code>st.title(\"Basic Demo\")\n\nfor event in agent_conversation.stream(): # (1)\n    event.render()\n\nif prompt := st.chat_input(\"Say something\"):\n    agent_conversation.run(prompt)\n    st.rerun()\n</code></pre> <ol> <li>This is a blocking iterator as long as the agent runs</li> </ol> <p>As you can see, the final code is quite straightforward. Like interacting with an agent directly, the process begins with an <code>st.chat_input</code>. However, instead of calling the <code>run</code> method on the agent itself, you now invoke it on the <code>agent_conversation</code> object. The <code>agent_conversation.stream()</code> method then yields all ongoing agent events in a blocking fashion, allowing you to render each event with a single command. Behind the scenes, this mechanism automatically calls the previously defined <code>render</code> methods for each event, ensuring a seamless and interactive user experience.</p>"},{"location":"examples/02_quizz/","title":"Quizz","text":""},{"location":"examples/02_quizz/#quizz-agent","title":"Quizz Agent","text":"<p>This examples demonstrates again delegating tool calls to the user and rendering of custom agent results. It's full code can be found here.</p> <p></p>"},{"location":"examples/02_quizz/#run-the-example","title":"Run the example","text":"<p>Before running the example, ensure that your OpenAI API key is set in the <code>OPENAI_API_KEY</code> environment variable. Once configured, you can start the demo using the following command:</p> uv run sync --all-groupsuv run streamlit run examples/02_quizz.py"},{"location":"examples/03_todo_list/","title":"Todo List","text":""},{"location":"examples/03_todo_list/#todo-list-agent","title":"Todo List Agent","text":"<p>This example demonstrates how to maintain a shared state between the UI and the agent, allowing the frontend to automatically update whenever the agent modifies the state. It's full code can be found here.</p> <p></p>"},{"location":"examples/03_todo_list/#run-the-example","title":"Run the example","text":"<p>Before running the example, ensure that your OpenAI API key is set in the <code>OPENAI_API_KEY</code> environment variable. Once configured, you can start the demo using the following command:</p> uv run sync --all-groupsuv run streamlit run examples/03_todo_list.py"},{"location":"features/","title":"Features","text":""},{"location":"getting_started/","title":"Getting Started","text":""},{"location":"getting_started/#getting-started","title":"Getting Started","text":"<p>\ud83d\udea7 Under Construction \ud83d\udea7</p>"}]}